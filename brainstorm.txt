Sound preprocessing strategies:
(to implement)

- allow varieed array lengths for keystrokes, don't fix at a given length.
  if identical length sound clips are necessary for training, append zeros as
  necessary

- record a long stretch of silence and calculate mean, max, standard deviation.
  use these values to evaluate noise and silence threshold for preprocessing

- algorithm improvement: calculate sample length, if sample_end doesn't fall under
  silence threshold, traverse array backwards until sample_end falls back under threshold
  and then some (possibly until right before threshold is exceeded again).

========================================================================================
Research Notes:
Zhuang, Zhou, Tygar - 
  - unsupervised methods

  - 10 min sound recording ->
    recovered up to 96% of typed chars
    90% of 5-char passwords within 20 attempts
    80% of 10-char passwords within 75 attempts
    Note: assuming 300 char/min, 30 different keys -> 100 variations of each key press

  - techniques used:
    > speed recognition techniques (cepstrum features)
    > hidden markov models
    > linear classification
    > feedback-based incremental learning

  - constraints:
    > 10 minutes sound clip (how many total key presses?)
    > assumes english text
    > testing set is same person, same keyboard, and same recording conditions as
      training set

  - attack procedure:
    1] feature extraction with ceptrum features. found that it performs better than FFT
    2] unsupervised key recognition (k-clustering for each keystroke, where k slightly
       greater than number of keys on keyboard)
       note: often imprecise categorization of keys to clustering classes. therefore, a
       particular key will be in each class with a certain probability. in well-clustered,
       clean data, probabilities of one or a couple classes will dominate for each key.
    3] hidden Markov model (HMM) to identify the classes to the key that was pressed.
       (takes into account sequence of typed letters)
       This step yielded 60% accuracy for chars, and 20% accuracy for words
    4] spelling and grammar checking. dictionary-based spelling and grammar correction as
       a single HMM (there are probably open-source tools for this in 2019)
       This step improves char accuracy to 70%, word accuracy to 50%
    5] feedback-based training produces a keystroke classifier not restricted to English
       spelling and grammar (useful for passwords).
       Basically, assume that "not-very-altered" words (because they're more likely to be
       correct) from last step as labeled training samples to train a classifier.
       This classifier recognizes the training samples again, which usually yields in higher
       keystroke accuracy rate (fewer corrections). this feedback loop is iterated until no
       significant improvement is gained.
       Classification methods used (linear classification, Gaussian mixtures). Both worked well.

  - technical details
    
    Keystroke Feature Extraction
      - typical user types 300 chars/min
      - keystrokes contain push + release (~100 ms)
      - requires detection of "start" of keystroke (=start of push peak)
      - calculate "windowed FFT" of signal and compare sum of all FFT coefficients to a
        threshold
      
      Note: FFT vs Cepstrum
      - Cepstrum features have been verified tobe more effective than plain FFT
      - Mel-Frequency Cepstral Coefficients (MFCC) was used
      - high frequency data apparently has limited value (ignored >12KHz)
      - after feature extraction, each keystroke is represented as a vector of 
        features (FFT coefficients of MFCCs)

    Unsupervised signal keystroke recognition
      - possible clustering methods: k-means, EM on Gaussian mixtures
      - tried k = 40 to 55, found that k = 50 yielded best results (30 keys, so k >=30)
      - larger k captures more info from sound samples, but is more sensitive to random noise
      - Markovian models are hard. (p. 4-5)
      - (not absolutely necessary) space bar sounds were marked manually. invaluable for word
        analysis and easy to distinguish. marked several dozen space keys,looked at the class
        that they were assigned, calculate estimated probabilities for class membership, and put
        these into Eta.
      - paper beilieves that automation of initializing Eta is possible in future work

    Spelling Error Correction with a Language Model
      - compute condtional probability of Y (classifier's guess) given each dictionary word X.
      - because of limited training data, there will be many zeros in confusion matrix E if
        used directly (E matrix is sparse). therefore, artificial occurrence count (0.1 was used)
        is assigned to each zero-occurrence event.
      - the points above assume that the plaintext is known. we don't have even a guess for the
        plaintext in the first iteration, so we assign E_ii = constant (0.5 was used) and distribute
        remaining 1 - constant uniformly above all other E_ij. feedback mechanism corrects this over
        time

    Grammar Error Correction with a Language Model
      - n-gram language model
      - infer the most likely sentence with Viterbi algorithm

    Supervised Training and Recognition
      - options: neural network, linear classification (assumes gaussian data, find hyperplanes to
        divide the classes), gaussian mixtures
      - gaussian mixtures assume each class corresponds to a mixture of gaussian distributions.
        this takes into accountthe fact that a key may have slightly different sounds depending on
        typing styling, direction it is hit


=================================================================================================
Road Map

1] Get comfortable with dev env (Jupyter, TensorFlow, NumPy, Matplotlib, etc)

2] Figure out a way to preprocess wave files of typing sounds. record wave file on garageband.
   Finding the initial press, clipping audio, reducing noise, manipulating the wave form,
   visualizing data.

3] Build out a classifier that can identify between a few keys after a supervised training session.

4] Build a classifier that can identify all keys decently after labeled training

5] Implement spelling and grammar correction mechanisms.

6] Attempt unsupervised clustering of key sounds, as discussed by Zhuang paper

7] Combine pipeline

